---
title: "Spatio-Temporal Data Analysis Project"
date: "`r Sys.Date()`"
output:
   pdf_document:
     fig_caption: true
     number_sections: true
fontsize: 12pt
---


![](./foscari.jpg)

# Patterns in foreign sims connected to OpenWiFi-Milan  {-}

Author: Bernardi Riccardo - 864018

\newpage
\tableofcontents
\newpage
<!-- \listoffigures -->
<!-- \newpage -->
<!-- \listoftables -->
<!-- \newpage -->

```{r include = FALSE}
knitr::opts_chunk$set(fig.width=10, fig.height=6, fig.path='Figs/',
                      echo=FALSE, warning=FALSE, message=FALSE)

rm(list=ls())
```


# Introduction & Motivation

The dataset that I've chosen is about the presence of foreign smartphone's sims to the OpenWifi of the Municipality of Milan. This data is open and available on the website data.gov.it. The reasons why I would like to go further with this project is that I strongly believe that are present seasonalities that can be interesting to be analysed but also can be more interesting to relate the outliers to some events that happened in the past with a certain mediatic relevance. In practice I would like to both analyse trend and seasonalities to know in which months there are more foreign people and if the trend is increasing in time and both search for outlier peaks to be related to important happenings in the Milan city. Finally I would like to forecast the possible presences in the new year in the city of Milan.


# The Data

The dataset comes from the open data provided by all the municipalities of Milan. This repository is available at dati.gov.it. From this repository I selected the data going from January of 2018 to October of the 2019.

Characteristics of the DataSet:

- the dataset contains 2 columns "Date, Number_of_Foreign_Sims"
- has 658 rows
- Dates goes from from 01/01/18 to 30/10/19 (~2 years)
- the datasets have no NA
- no lacking days
- the "Number_of_Foreign_Sims" is a discrete variable about total number of foreign sims in a certain Date connected to the OpenWifi of Milan


```{r}
setwd("~/Documents/GitHub/STDA-project-proposal")
set.seed(25061997)

require(zoo)
require(xts)
data <- read.csv("opendatamilano2017.csv",sep = ";")
data <- rbind(data, read.csv("opendatamilano2018.csv",sep = ";"))
data <- rbind(data, read.csv("opendatamilano2019.csv",sep = ";"))

data$prefix <- NULL
data$country <- NULL
data$num <- NULL
data$total.ita.sim <- NULL

ll <- aggregate.data.frame(data$total.foreign.sim,by=list(data$date),FUN=mean)
names(ll)[2] <- "total.foreign.sim"
names(ll)[1] <- "Date"
data <- ll
```

# Exploration of the Data

```{r}
print("minimum, lower-hinge, median, upper-hinge, maximum)")
fivenum(data$total.foreign.sim)
```

```{r}
hist(data$total.foreign.sim)
```


# Preprocessing

Checking Nans

```{r}
sum(is.na(data$Date))
sum(is.na(data$total.foreign.sim))
```

Checking limit values

```{r}
min(data$total.foreign.sim)
max(data$total.foreign.sim)
```

```{r}
mean(data$total.foreign.sim)
mean.data <- mean(data$total.foreign.sim)
```

```{r}
sd(data$total.foreign.sim)
sd.data <- sd(data$total.foreign.sim)
```

Elements that are good in our ts stand between mean$\pm$std

```{r}
up.m.sd <- mean.data + sd.data
lo.m.sd <- mean.data - sd.data

up.m.sd
lo.m.sd
```


boxplot to check outliers


```{r}
boxplot(data$total.foreign.sim)
```

```{r}
qs <- quantile(data$total.foreign.sim)
qs
iqr <- IQR(data$total.foreign.sim)
low.outlier <- qs[2] - (1.5 * iqr)
hi.outlier <- qs[4] + (1.5 * iqr)

low.outlier
hi.outlier
```

```{r}
data$total.foreign.sim[data$total.foreign.sim<low.outlier] = mean.data
data$total.foreign.sim[data$total.foreign.sim>hi.outlier] = mean.data
```

Checking last elements of the serie

```{r}
last5 <- data$total.foreign.sim[seq(from=length(data$total.foreign.sim)-5, to=length(data$total.foreign.sim), by=1)]
last5[last5<lo.m.sd] <- mean.data
data$total.foreign.sim[seq(from=length(data$total.foreign.sim)-5, to=length(data$total.foreign.sim), by=1)] <- last5
```


# Using a boxCox transform

```{r}
#data$total.foreign.sim <- log(data$total.foreign.sim)
data$total.foreign.sim <- sqrt(data$total.foreign.sim)
```

# Hist after the transformation

```{r}
hist(data$total.foreign.sim)
```

# Boxplot after the transformation

```{r}
boxplot(data$total.foreign.sim)
```

# Time serie is built

Here the time serie is built

```{r}
require(xts)
data$Date <- as.Date(data$Date, format = "%Y-%m-%d")
#typeof(data$date[1])
data.xts <- xts(data$total.foreign.sim, order.by=data$Date, frequency = 7)
data.ts <- ts(data$total.foreign.sim, frequency = 30)
```

We loaded the dataset from the various datasets aggregating into only one dataset with 655 rows representing 2 years of data gathered. Starting from 05.06.2017 to 30.10.2019. Data is here:

```{r}
main <- "foreign sim per day"
ylab<-"Tot of sim in that day"
plot(data.xts,ylab=ylab,main=main)
```



```{r}
main <- "foreign sim per day"
ylab<-"Tot of sim in that day"
plot(data.ts,ylab=ylab,main=main)
```


# Month by month plot

```{r}
boxplot(data.ts~cycle(data.ts))
```

# Peaks Explanation

Many peaks are present we would like to exaplin them and to cut them out to be able to predict with a simple arima

- automatic roaming [https://www.mobileworld.it/2017/08/07/roaming-gratis-europa-condizioni-fair-use-114077/]
- fashion week [https://www.cameramoda.it/it/milano-moda-donna/] february
- fashion week 2017 [https://www.milanoweekend.it/articoli/milano-fashion-week-2017-eventi-programma/] february

```{r}
a <- max(data$total.foreign.sim)
data$Date[data$total.foreign.sim==a]
```

- arch week [https://www.lastampa.it/milano/2017/06/17/news/milano-smart-city-del-futuro-se-ne-parla-all-archweek-in-triennale-1.34584894?refresh_ce]
- it was a saturday!!
- it was the orient festival [https://www.wikieventi.it/milano/index.php?data_selezionata=2017-06-17]
- many mucis events, samsara of papetee and others, folk's festivals, discounts [https://www.wikieventi.it/milano/index.php?data_selezionata=2017-07-22]

# Trend recognition

```{r}
tt<-as.numeric(time(data.ts))
fit2<-lm(data.ts~poly(tt,degree=2,raw=TRUE))
fit4<-lm(data.ts~poly(tt,degree=8,raw=TRUE))

main <- "foreign sim per day"
plot(data.ts,ylab=ylab,main=main)
lines(tt,predict(fit2),col='red',lwd=2)
lines(tt,predict(fit4),col='blue',lwd=2)
legend("bottomright",legend = c("2nd order","4th order"),lwd=2,lty=1,col=c("red","blue"))
```

# Smoothing

```{r}
require(fpp)
require(forecast)
trendpattern = timeSeries::filter(data.ts, filter = rep(1/15,15), sides=2)
plot(data.ts, main = "moving average annual trend")
lines(trendpattern,col="red")
```

```{r}
seasonality <- data.ts - trendpattern
plot(seasonality)
```


# Detrending using LM

```{r}
require(fpp)
#data.ts <- data.ts - ma(data.ts, order = 3, centre = T)
#data.ts <- data.ts - predict(fit4)
#plot(data.ts)
```

# Derivative to avoid stationarity

```{r}
#data.ts.diff <- diff(detrended.lin)
#plot(data.ts.diff)
#data.ts <- data.ts.diff
```

# Checking stationarity before entering arima

```{r}
# lb <- Box.test(residuals(fit), lag = 24, type = "Ljung-Box")
# lb
# bp <- Box.test(residuals(fit), lag = 24, type = "Box-Pierce")
# bp
```

# Splitting

```{r}
require(TSstudio)
split <- ts_split(ts.obj = data.ts, sample.out = 100)

data.ts <- split$train
testing <- split$test
```

# Auto Arima

```{r}
require(fpp)
require(forecast)
fit <- auto.arima(data.ts,stepwise=TRUE,trace=TRUE,ic = "bic", approximation = FALSE)
```


```{r}
plot(forecast(fit))
```

```{r}
#training <- subset(auscafe, end=length(auscafe)-61)
#test <- subset(auscafe, start=length(auscafe)-60)
#cafe.train <- Arima(training, order=c(2,1,1),seasonal=c(0,1,2), lambda=0)
data.ts %>% forecast(h=100) %>% autoplot() + autolayer(testing)
```


```{r}
pred <- forecast(fit, h=100)
accuracy(pred, testing)
```


```{r}
tsdisplay(residuals(fit))
```

```{r}
lb <- Box.test(residuals(fit), lag = 24, type = "Ljung-Box")
lb
```

```{r}
bp <- Box.test(residuals(fit), lag = 24, type = "Box-Pierce")
bp
```

```{r}
########################################################
#### Residuals diagnostics in forecasting
########################################################

res.fr <- residuals(pred)

par(mfrow=c(1,3))

plot(res.fr, main="Residuals from ARIMA method",
  ylab="", xlab="Years")

Acf(res.fr, main="ACF of residuals")

u <- residuals(fit)

m<-mean(u)
std<-sqrt(var(u))
hist(u, breaks=20, col="gray", prob=TRUE, 
xlab="Residuals", main="Histogram of residuals\n with Normal Curve")
curve(dnorm(x, mean=m, sd=std), 
      col="black", lwd=2, add=TRUE)
```

```{r}
library(tseries)
kpss.test(diff(data.ts))
ndiffs(data.ts)
plot(data.ts)
```


The plot is not good but AIC and BIC are very high, we should try with a multi seasonal decomposition

```{r}
frequency(data.ts)
```

# Searching for multi seasonalities

without differentiation residuals looks pretty bad

```{r}
library(lubridate)
library(dplyr)
library(forecast)
library(ggplot2)
library(scales)

data.ts %>% decompose(type="multiplicative") %>% autoplot()
dec <- decompose(data.ts)
acf(na.omit(dec$random), lag.max = 30)
```

Looks better than before but we can still see every 5(\*7) a seasonality/trend left. 5\*7 is about a month, probably there is a monthly seasonality

# RUGARCH

```{r}
require(rugarch)
spec = ugarchspec()
fit = ugarchfit(spec = spec, data = data.ts)
show(fit)
```


```{r}
plot(fit, which='all')
```



# Conclusions


It was a hard work! I tried a lot of methods to fit the data and obtain good forecasting and good residuals. I tried searching for multi seasonalities, difference some times to reach stationarity, detrending with lm and ma, smoothing. I tried by hand many arima models. I tried to decompose the time serie in many ways. I tried all the possible frequencies that can be thought as valid. Eventually it was really interesting! I experimented a lot. The dataset is brand new, never touched by other data scientists for what i know.


# TODO

prima diff, poi prima diff seasonal, check acf pacf, check no trend(trend se con decadono a 0 velocemente)
identificare i picchi
identificare l estate
doppia seasonality una settimanale e una annuale
ARCH
GARCH
VAR<----
stabilizzare con trasformazioni
