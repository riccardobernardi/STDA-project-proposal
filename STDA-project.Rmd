---
title: "Spatio-Temporal Data Analysis Project"
date: "`r Sys.Date()`"
output:
   pdf_document:
     fig_caption: true
     number_sections: true
fontsize: 12pt
---


![](./foscari.jpg)

# Patterns in foreign sims connected to OpenWiFi-Milan  {-}

Author: Bernardi Riccardo - 864018

\newpage
\tableofcontents
\newpage
<!-- \listoffigures -->
<!-- \newpage -->
<!-- \listoftables -->
<!-- \newpage -->

```{r include = FALSE}
knitr::opts_chunk$set(fig.width=10, fig.height=6, fig.path='Figs/',
                      echo=FALSE, warning=FALSE, message=FALSE)
```


# Introduction & Motivation

The dataset that I've chosen is about the presence of foreign smartphone's sims to the OpenWifi of the Municipality of Milan. This data is open and available on the website data.gov.it. The reasons why I would like to go further with this project is that I strongly believe that are present seasonalities that can be interesting to be analysed but also can be more interesting to relate the outliers to some events that happened in the past with a certain mediatic relevance. In practice I would like to both analyse trend and seasonalities to know in which months there are more foreign people and if the trend is increasing in time and both search for outlier peaks to be related to important happenings in the Milan city. Finally I would like to forecast the possible presences in the new year in the city of Milan.


# The Data

The dataset comes from the open data provided by all the municipalities of Milan. This repository is available at dati.gov.it. From this repository I selected the data going from January of 2018 to October of the 2019.

Characteristics of the DataSet:

- the dataset contains 2 columns "Date, Number_of_Foreign_Sims"
- has 658 rows
- Dates goes from from 01/01/18 to 30/10/19 (~2 years)
- the datasets have no NA
- no lacking days
- the "Number_of_Foreign_Sims" is a discrete variable about total number of foreign sims in a certain Date connected to the OpenWifi of Milan


```{r}
setwd("~/Documents/GitHub/STDA-project-proposal")
set.seed(25061997)

require(zoo)
require(xts)
data <- read.csv("opendatamilano2017.csv",sep = ";")
data <- rbind(data, read.csv("opendatamilano2018.csv",sep = ";"))
data <- rbind(data, read.csv("opendatamilano2019.csv",sep = ";"))

data$prefix <- NULL
data$country <- NULL
data$num <- NULL
data$total.ita.sim <- NULL

ll <- aggregate.data.frame(data$total.foreign.sim,by=list(data$date),FUN=mean)
names(ll)[2] <- "total.foreign.sim"
names(ll)[1] <- "Date"
data <- ll

data$Date <- as.Date(data$Date, format = "%Y-%m-%d")
#typeof(data$date[1])
data.xts <- xts(data$total.foreign.sim, order.by=data$Date, frequency = 30)
data.ts <- ts(data$total.foreign.sim, frequency = 30)
```

# Exploration of the Data

```{r}
print("minimum, lower-hinge, median, upper-hinge, maximum)")
fivenum(data$total.foreign.sim)
```

```{r}
hist(data$total.foreign.sim)
```

We loaded the dataset from the various datasets aggregating into only one dataset with 655 rows representing 2 years of data gathered. Starting from 01.01.2018 to 30.10.2019. Data is here:

```{r}
main <- "foreign sim per day"
ylab<-"Tot of sim in that day"
plot(data.xts,ylab=ylab,main=main)
```


# Peaks Explanation

Many peaks are present we would like to exaplin them and to cut them out to be able to predict with a simple arima

- automatic roaming [https://www.mobileworld.it/2017/08/07/roaming-gratis-europa-condizioni-fair-use-114077/]
- fashion week [https://www.cameramoda.it/it/milano-moda-donna/] february
- fashion week 2017 [https://www.milanoweekend.it/articoli/milano-fashion-week-2017-eventi-programma/] february

```{r}
a <- max(data$total.foreign.sim)
data$Date[data$total.foreign.sim==a]
```

- arch week [https://www.lastampa.it/milano/2017/06/17/news/milano-smart-city-del-futuro-se-ne-parla-all-archweek-in-triennale-1.34584894?refresh_ce]
- it was a saturday!!
- it was the orient festival [https://www.wikieventi.it/milano/index.php?data_selezionata=2017-06-17]
- many mucis events, samsara of papetee and others, folk's festivals, discounts [https://www.wikieventi.it/milano/index.php?data_selezionata=2017-07-22]

# Outlier detection and removal

Here is not ready, should be completed asap

# Trend recognition

```{r}
tt<-as.numeric(time(data.ts))
fit2<-lm(data.ts~poly(tt,degree=2,raw=TRUE))
fit4<-lm(data.ts~poly(tt,degree=8,raw=TRUE))

main <- "foreign sim per day"
plot(data.ts,ylab=ylab,main=main)
lines(tt,predict(fit2),col='red',lwd=2)
lines(tt,predict(fit4),col='blue',lwd=2)
legend("bottomright",legend = c("2nd order","4th order"),lwd=2,lty=1,col=c("red","blue"))
```





## Detrending using LM

```{r}
require(fpp)
detrended.lin <- data.ts - ma(data.ts, order = 7, centre = T)
#detrended.lin <- data.ts - predict(fit4)
plot(detrended.lin)
```

# Removing seasonality

A good idea is to differenciate before decomposing. With the multiplicative model

```{r}
differenced <- diff(data.ts)
plot(differenced)
```

```{r}
min(differenced)
```

```{r}
max(differenced)
```



```{r}
decomposed <- decompose(differenced,type = "multiplicative")
```


```{r}
#plot(decomposed)
```



```{r}
#checkresiduals(decomposed$random)

Box.test(decomposed$random, lag=5, fitdf=0)
Box.test(decomposed$random, lag=5, fitdf=0, type="Lj")
```

# The additive model doesn't work for us

With the additive model
This model doesn't work at all

```{r}
differenced <- diff(data.ts)
plot(differenced)

decomposed <- decompose(differenced,type = "additive")
plot(decomposed)

checkresiduals(decomposed$random)

Box.test(decomposed$random, lag=5, fitdf=0)
Box.test(decomposed$random, lag=5, fitdf=0, type="Lj")
```

Without the first differentiation the result will have been much worse:

```{r}
not.differenced <- data.ts
plot(not.differenced)

decomposed <- decompose(not.differenced,type = "multiplicative")
plot(decomposed)

checkresiduals(decomposed$random)

Box.test(decomposed$random, lag=5, fitdf=0)
Box.test(decomposed$random, lag=5, fitdf=0, type="Lj")
```

Every 7 lags the peak recurs

# Check Residuals

```{r}
acf(na.omit(decomposed$random), main = "Standardized Residuals", 36)
```


```{r}
pacf(na.omit(decomposed$random), main = "Standardized Residuals", 36)
```

# Arima

```{r}
require(fpp)
fit <- Arima(differenced, order=c(3,1,3))
summary(fit)
```

```{r}
checkresiduals(fit)
```

```{r}
autoplot(forecast(fit))
```


# Auto Arima


```{r}
require(fpp)
auto.arima(data.ts,stepwise=TRUE,trace=TRUE,ic = "bic")
aa <- Arima(order = c(3,1,1), seasonal = c(2,0,0), y = data.ts)
```

```{r}
plot(forecast(aa,data.ts))
```

The plot is not good but AIC and BIC are very high, we should try with a multi seasonal decomposition

```{r}
frequency(data.ts)
```


# Searching for multi seasonalities

without differentiation residuals looks pretty bad

```{r}
library(lubridate)
library(dplyr)
library(forecast)
library(ggplot2)
library(scales)

data.ts %>% decompose(type="multiplicative") %>% autoplot()
dec <- decompose(data.ts)
acf(na.omit(dec$random), lag.max = 30)
```

trying with differentiation and a multiplicative model:

```{r}
#differenced %>% decompose(type="multiplicative") %>% autoplot()
#dec <- decompose(differenced,type="multiplicative")
#acf(na.omit(dec$random))
```

Looks better than before but we can still see every 5(\*7) a seasonality/trend left. 5\*7 is about a month, probably there is a monthly seasonality

# Transforming into msts


```{r}
require(forecast)
msts_cons <- msts(as.data.frame(diff(data.ts)), seasonal.periods = c(7,365))
msts_cons %>% mstl() %>% autoplot()
decomposed <- mstl(msts_cons)
```

```{r}
checkresiduals(remainder(decomposed))
Box.test(remainder(decomposed), lag=5, fitdf=0)
Box.test(remainder(decomposed), lag=5, fitdf=0, type="Lj")
```


# Garch


```{r}
library(fGarch) # estimate GARCH and Forecast
library(tseries) #used for time series data
library(urca) #Used for checking Unit root Cointegration
library(fUnitRoots) #Used for conducting unit root test
library(forecast) #Used for forecasting ARIMA model
```

```{r}
setwd("~/Documents/GitHub/STDA-project-proposal")
set.seed(25061997)

require(zoo)
require(xts)
data <- read.csv("opendatamilano2017.csv",sep = ";")
data <- rbind(data, read.csv("opendatamilano2018.csv",sep = ";"))
data <- rbind(data, read.csv("opendatamilano2019.csv",sep = ";"))

data$prefix <- NULL
data$country <- NULL
data$num <- NULL
data$total.ita.sim <- NULL

ll <- aggregate.data.frame(data$total.foreign.sim,by=list(data$date),FUN=mean)
names(ll)[2] <- "total.foreign.sim"
names(ll)[1] <- "Date"
data <- ll

data$Date <- as.Date(data$Date, format = "%Y-%m-%d")
#typeof(data$date[1])
data.xts <- xts(data$total.foreign.sim, order.by=data$Date, frequency = 30)
data.ts <- ts(data$total.foreign.sim, frequency = 30)
```


```{r}
#Calculate inflation as difference of log of exchange rate and then multiplied by 100
inflation_series<-(diff(log(data.ts)))*100 
#Plot the inflation 
plot.ts(inflation_series, main="Inflation of exchange rate")
```

```{r}
summary(inflation_series)
```

```{r}
#ACF and PACF Plots
acf(inflation_series)
pacf(inflation_series)
```

```{r}
#Model fitting. We have selected the ARIMA(5,0,0) model
Arima_5_0_0<- arima(inflation_series[1:499], order = c(5,0,0))
#Check out the residuals 
residual <- Arima_5_0_0$resid
acf(residual) 
pacf(residual)
```

```{r}
#Perform the Ljung Box test
Box.test(residual,c(20),"Ljung-Box")
```


```{r}
#Fitting GARCH over the first 500 data points
garch.fit <- garchFit(formula = ~arma(5,0)+garch(1,1), data = inflation_series[1:500])
```

```{r}
#Plot the model
plot(garch.fit, which='all')
```


# RUGARCH

```{r}
require(rugarch)
spec = ugarchspec()
fit = ugarchfit(spec = spec, data = data.ts)
show(fit)
```


```{r}
plot(fit, which='all')
```



# Conclusions


It was really interesting!


# TODO

prima diff, poi prima diff seasonal, check acf pacf, check no trend(trend se con decadono a 0 velocemente)
identificare i picchi
identificare l estate
doppia seasonality una settimanale e una annuale
ARCH
GARCH
VAR<----
stabilizzare con trasformazioni
